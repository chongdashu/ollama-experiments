{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap\n",
    "!pip3 install -U bitsandbytes\n",
    "!pip3 install -U pef\n",
    "!pip3 install -U trl\n",
    "!pip3 install -U accelerate\n",
    "!pip3 install -U datasets\n",
    "!pip3 install -U transformers\n",
    "!pip3 install langchain sentence-transformers chromadb langchainhub\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pip.log\", \"w\") as file:\n",
    "    file.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model we want\n",
    "model = \"gemma:2b-instruct\"\n",
    "\n",
    "# Connect to the Ollama isntance\n",
    "llm = Ollama(model=model)\n",
    "\n",
    "# Have a basic prompt\n",
    "prompt = \"Tell me a joke\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invoking prompt: 'Tell me a joke' ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the math book look so sad?\n",
      "\n",
      "Because of all of its problems!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Why did the math book look so sad?\\n\\nBecause of all of its problems.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Invoke with a prompt, response as a whole.\n",
    "print(f\"Invoking prompt: '{prompt}' ...\")\n",
    "response = llm.invoke(prompt)\n",
    "print(response)\n",
    "llm.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming response for prompt: 'Tell me a joke' ...\n",
      "Why did the math book look so sad?\n",
      "\n",
      "Because of all of its problems!"
     ]
    }
   ],
   "source": [
    "chunks = []\n",
    "print(f\"Streaming response for prompt: '{prompt}' ...\")\n",
    "for chunk in llm.stream(prompt):\n",
    "    chunks.append(chunk)\n",
    "    print(chunk, end=\"\", flush=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Who won the FIFA World Cup in the year 1994?', 'text': 'The provided text does not contain any information regarding the FIFA World Cup winner in 1994, so I am unable to answer this question from the provided context.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "question = \"Who won the FIFA World Cup in the year 1994?\"\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "print(llm_chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[GenerationChunk(text='**Step 1: Understanding the concept of Kaggle.**\\n\\n- Kaggle is a platform that provides a platform for data science and machine learning communities to collaborate, compete, and share datasets.\\n\\n\\n**Step 2: Defining its purpose.**\\n\\n- Kaggle is primarily known for hosting competitions and providing access to datasets relevant to various data science and machine learning tasks.\\n\\n\\n**Step 3: Recognizing its significance.**\\n\\n- Kaggle serves as a valuable resource for data enthusiasts, professionals, and organizations to enhance their skills, explore new ideas, and compete in meaningful challenges.\\n\\n\\n**Step 4: Understanding its key features.**\\n\\n- Kaggle offers a variety of features, including:\\n    - Competitions with predefined datasets and tasks\\n    - Datasets categorized by domain and industry\\n    - Opportunity to collaborate with other data scientists and learn from their expertise\\n    - Access to tools and resources for data exploration, modeling, and evaluation\\n\\n\\n**Step 5: Recognizing its impact.**\\n\\n- Kaggle plays a significant role in:\\n    - Fostering data science and machine learning innovation\\n    - Promoting knowledge sharing and knowledge discovery\\n    - Supporting the development of new data-driven solutions', generation_info={'model': 'gemma:2b-instruct', 'created_at': '2024-05-28T14:40:38.106730281Z', 'response': '', 'done': True, 'done_reason': 'stop', 'context': [106, 1645, 108, 9413, 235292, 2439, 603, 80600, 2315, 235336, 109, 1261, 235292, 4371, 235303, 235256, 1742, 4065, 731, 4065, 235265, 107, 108, 106, 2516, 108, 688, 5856, 235248, 235274, 235292, 40371, 573, 7819, 576, 80600, 2315, 116742, 109, 235290, 80600, 2315, 603, 476, 7134, 674, 6572, 476, 7134, 604, 1423, 8042, 578, 6479, 6044, 11707, 577, 64185, 235269, 26046, 235269, 578, 4638, 47927, 235265, 110, 688, 5856, 235248, 235284, 235292, 109726, 1277, 6187, 116742, 109, 235290, 80600, 2315, 603, 17022, 3836, 604, 28960, 49603, 578, 9151, 3684, 577, 47927, 9666, 577, 4282, 1423, 8042, 578, 6479, 6044, 13333, 235265, 110, 688, 5856, 235248, 235304, 235292, 170109, 1277, 18279, 116742, 109, 235290, 80600, 2315, 19179, 685, 476, 14222, 6537, 604, 1423, 68210, 235269, 19097, 235269, 578, 12140, 577, 14915, 1024, 7841, 235269, 15370, 888, 5793, 235269, 578, 26046, 575, 28829, 12382, 235265, 110, 688, 5856, 235248, 235310, 235292, 40371, 1277, 2621, 5119, 116742, 109, 235290, 80600, 2315, 6952, 476, 8080, 576, 5119, 235269, 3359, 235292, 108, 141, 235290, 204459, 675, 124725, 47927, 578, 13333, 108, 141, 235290, 199939, 89096, 731, 11988, 578, 5361, 108, 141, 235290, 55925, 577, 64185, 675, 1156, 1423, 21904, 578, 3918, 774, 1024, 21572, 108, 141, 235290, 11499, 577, 8112, 578, 6336, 604, 1423, 29787, 235269, 27723, 235269, 578, 13167, 110, 688, 5856, 235248, 235308, 235292, 170109, 1277, 6418, 116742, 109, 235290, 80600, 2315, 12258, 476, 4937, 4731, 575, 235292, 108, 141, 235290, 185120, 3556, 1423, 8042, 578, 6479, 6044, 19764, 108, 141, 235290, 136145, 5567, 11766, 578, 5567, 19182, 108, 141, 235290, 65314, 573, 3505, 576, 888, 1423, 235290, 37372, 8319, 107, 108], 'total_duration': 40859033545, 'load_duration': 2701170745, 'prompt_eval_count': 27, 'prompt_eval_duration': 1845100000, 'eval_count': 241, 'eval_duration': 36311760000})], [GenerationChunk(text=\"**Step 1: Explore the Kaggle platform and resources.**\\n\\n* Visit the Kaggle homepage and navigate through the different sections.\\n* Discover the types of datasets, competitions, and communities available.\\n* Learn about the platform's features and how it facilitates data science tasks.\\n\\n**Step 2: Identify a specific dataset that interests you.**\\n\\n* Choose a dataset that aligns with your skills and interests.\\n* Consider the dataset size, quality, and relevance to your area of interest.\\n\\n**Step 3: Review the competition guidelines and submission requirements.**\\n\\n* Understand the problem statement and objectives.\\n* Determine the type of model or solution expected.\\n* Familiarize yourself with the evaluation metrics and scoring criteria.\\n\\n**Step 4: Explore the community discussions and resources.**\\n\\n* Join the Kaggle community forum to engage with other data scientists.\\n* Search for tutorials, documentation, and solutions to common challenges.\\n\\n**Step 5: Set up your workspace and prepare your data.**\\n\\n* Create a new Kaggle notebook or upload your own data.\\n* Ensure your data is clean, organized, and relevant.\\n\\n**Step 6: Start exploring and learning.**\\n\\n* Begin familiarizing yourself with the dataset and competition.\\n* Read the documentation and explore the code examples.\\n* Experiment with different techniques and explore potential solutions.\", generation_info={'model': 'gemma:2b-instruct', 'created_at': '2024-05-28T14:41:22.868051881Z', 'response': '', 'done': True, 'done_reason': 'stop', 'context': [106, 1645, 108, 9413, 235292, 2439, 603, 573, 1370, 4065, 590, 1412, 1987, 611, 80600, 2315, 235336, 109, 1261, 235292, 4371, 235303, 235256, 1742, 4065, 731, 4065, 235265, 107, 108, 106, 2516, 108, 688, 5856, 235248, 235274, 235292, 28942, 573, 80600, 2315, 7134, 578, 6336, 116742, 109, 235287, 21086, 573, 80600, 2315, 56400, 578, 31201, 1593, 573, 2167, 12487, 235265, 108, 235287, 37321, 573, 5088, 576, 47927, 235269, 49603, 235269, 578, 11707, 2506, 235265, 108, 235287, 17090, 1105, 573, 7134, 235303, 235256, 5119, 578, 1368, 665, 81504, 1423, 8042, 13333, 235265, 109, 688, 5856, 235248, 235284, 235292, 41038, 476, 3724, 20884, 674, 10714, 692, 116742, 109, 235287, 19262, 476, 20884, 674, 162269, 675, 861, 7841, 578, 10714, 235265, 108, 235287, 15320, 573, 20884, 2395, 235269, 3614, 235269, 578, 45471, 577, 861, 2713, 576, 3273, 235265, 109, 688, 5856, 235248, 235304, 235292, 5973, 573, 11010, 17923, 578, 26970, 7493, 116742, 109, 235287, 54159, 573, 3210, 6218, 578, 17122, 235265, 108, 235287, 40647, 573, 1916, 576, 2091, 689, 4558, 5043, 235265, 108, 235287, 106991, 889, 5804, 675, 573, 13167, 30660, 578, 21949, 12830, 235265, 109, 688, 5856, 235248, 235310, 235292, 28942, 573, 4159, 21505, 578, 6336, 116742, 109, 235287, 20470, 573, 80600, 2315, 4159, 16875, 577, 18254, 675, 1156, 1423, 21904, 235265, 108, 235287, 10552, 604, 60820, 235269, 18312, 235269, 578, 8319, 577, 3818, 12382, 235265, 109, 688, 5856, 235248, 235308, 235292, 4218, 908, 861, 59600, 578, 12523, 861, 1423, 116742, 109, 235287, 7319, 476, 888, 80600, 2315, 31916, 689, 16783, 861, 1997, 1423, 235265, 108, 235287, 45409, 861, 1423, 603, 3903, 235269, 16010, 235269, 578, 9666, 235265, 109, 688, 5856, 235248, 235318, 235292, 7248, 31210, 578, 6044, 116742, 109, 235287, 18387, 10709, 6935, 5804, 675, 573, 20884, 578, 11010, 235265, 108, 235287, 4814, 573, 18312, 578, 15370, 573, 3409, 8944, 235265, 108, 235287, 30199, 675, 2167, 10423, 578, 15370, 5736, 8319, 235265, 107, 108], 'total_duration': 44714362724, 'load_duration': 41591373, 'prompt_eval_count': 26, 'prompt_eval_duration': 1936841000, 'eval_count': 279, 'eval_duration': 42687482000})], [GenerationChunk(text=\"This is a good response as it acknowledges the user's action and proposes a subsequent step. It also maintains a positive and helpful tone.\", generation_info={'model': 'gemma:2b-instruct', 'created_at': '2024-05-28T14:41:28.571455738Z', 'response': '', 'done': True, 'done_reason': 'stop', 'context': [106, 1645, 108, 9413, 235292, 590, 7599, 861, 12027, 235265, 2439, 1412, 590, 749, 2351, 235336, 109, 1261, 235292, 4371, 235303, 235256, 1742, 4065, 731, 4065, 235265, 107, 108, 106, 2516, 108, 1596, 603, 476, 1426, 3590, 685, 665, 81258, 573, 2425, 235303, 235256, 3105, 578, 61590, 476, 17160, 4065, 235265, 1165, 1170, 40938, 476, 6222, 578, 10055, 14533, 235265, 107, 108], 'total_duration': 5653446246, 'load_duration': 41255745, 'prompt_eval_count': 27, 'prompt_eval_duration': 1908484000, 'eval_count': 29, 'eval_duration': 3658593000})]]\n"
     ]
    }
   ],
   "source": [
    "qs = [\n",
    "    {'question': \"What is Kaggle?\"},\n",
    "    {'question': \"What is the first step I should take on Kaggle?\"},\n",
    "    {'question': \"I followed your instructions. What should I do next?\"}\n",
    "]\n",
    "\n",
    "res = llm_chain.generate(qs)\n",
    "print(res.generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### With Context Inlined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Platform:** Kaggle\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the question based on the context below. If the question cannot be answered using the information provided, answer with \"I don't know\".\n",
    "\n",
    "Context: Kaggle is a platform for data science and machine learning competitions, where users can find and publish datasets, explore and build models in a web-based data science environment, and work with other data scientists and machine learning engineers. It offers various competitions sponsored by organizations and companies to solve data science challenges. Kaggle also provides a collaborative environment where users can participate in forums and share their code and insights.\n",
    "\n",
    "Question: Which platform provides datasets, machine learning competitions, and a collaborative environment for data scientists?\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "print(llm.invoke(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FewShot (i.e. with some examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Overall Tone:** Informative, encouraging, and supportive.\n",
      "\n",
      "**Specific Responses:**\n",
      "\n",
      "**How do I start with Kaggle competitions?**\n",
      "- Start by selecting a competition that resonates with you and aligns with your skill level.\n",
      "\n",
      "**What should I do if my model isn't performing well?**\n",
      "- Explore various models, refine hyperparameters, and consult forums for insights.\n",
      "\n",
      "**How can I find a team to join on Kaggle?**\n",
      "- Explore competition discussion forums to identify potential team members.\n",
      "- Post your interest in joining a team.\n",
      "\n",
      "**Is participating in Kaggle competitions worth my time?**\n",
      "- Yes, participating in Kaggle competitions offers valuable learning and networking opportunities.\n"
     ]
    }
   ],
   "source": [
    "# Import the FewShotPromptTemplate class from langchain module\n",
    "from langchain import FewShotPromptTemplate\n",
    "\n",
    "# Define examples that include user queries and AI's answers specific to Kaggle competitions\n",
    "examples = [\n",
    "    {\n",
    "        \"query\": \"How do I start with Kaggle competitions?\",\n",
    "        \"answer\": \"Start by picking a competition that interests you and suits your skill level. Don't worry about winning; focus on learning and improving your skills.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What should I do if my model isn't performing well?\",\n",
    "        \"answer\": \"It's all part of the process! Try exploring different models, tuning your hyperparameters, and don't forget to check the forums for tips from other Kagglers.\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How can I find a team to join on Kaggle?\",\n",
    "        \"answer\": \"Check out the competition's discussion forums. Many teams look for members there, or you can post your own interest in joining a team. It's a great way to learn from others and share your skills.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define the format for how each example should be presented in the prompt\n",
    "example_template = \"\"\"\n",
    "User: {query}\n",
    "AI: {answer}\n",
    "\"\"\"\n",
    "\n",
    "# Create an instance of PromptTemplate for formatting the examples\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=['query', 'answer'],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# Define the prefix to introduce the context of the conversation examples\n",
    "prefix = \"\"\"The following are excerpts from conversations with an AI assistant focused on Kaggle competitions.\n",
    "The assistant is typically informative and encouraging, providing insightful and motivational responses to the user's questions about Kaggle. Here are some examples:\n",
    "\"\"\"\n",
    "\n",
    "# Define the suffix that specifies the format for presenting the new query to the AI\n",
    "suffix = \"\"\"\n",
    "User: {query}\n",
    "AI: \"\"\"\n",
    "\n",
    "# Create an instance of FewShotPromptTemplate with the defined examples, templates, and formatting\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "query = \"Is participating in Kaggle competitions worth my time?\"\n",
    "\n",
    "print(llm.invoke(few_shot_prompt_template.format(query=query)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
